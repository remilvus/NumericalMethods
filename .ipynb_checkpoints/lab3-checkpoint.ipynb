{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GjLwr7LHju9z"
   },
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Y0Y7HX_yju91"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mkl\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "np.random.seed(1234)\n",
    "mkl.set_num_threads(4)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usefull imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn\n",
    "from scipy.stats import norm as normal_dist\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot 'iso-densities' for MVN\n",
    "#   ax - axis for plotting,\n",
    "#   mu, Sigma - MVN parameters,\n",
    "#   title - plot title.\n",
    "def plot_mvn(ax, mu, Sigma, title = None, grid_size = 100):\n",
    "    mu = np.squeeze(mu)\n",
    "    mu_x, mu_y = mu[0], mu[1]\n",
    "    s_x, s_y = np.sqrt(Sigma[0, 0]), np.sqrt(Sigma[1, 1])\n",
    "    \n",
    "    xmin, xmax = mu_x-3*s_x, mu_x+3*s_x\n",
    "    ymin, ymax = mu_y-3*s_y, mu_y+3*s_y\n",
    "    \n",
    "    X = np.linspace(xmin, xmax, grid_size)\n",
    "    Y = np.linspace(ymin, ymax, grid_size)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    grid = np.vstack([X.flatten(), Y.flatten()]).T\n",
    "    \n",
    "    p = mvn(mu, Sigma)\n",
    "    density = p.pdf(grid).reshape((grid_size, grid_size))\n",
    "\n",
    "    ax.contour(X, Y, density, zorder=1)\n",
    "    \n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot a linear regression fit\n",
    "#   ax - axis for plotting,\n",
    "#   w - linear regression parameters\n",
    "#   data_x, data_y, data_ys - explanatory variables, responses and their uncertainties (data)\n",
    "#   test_x, test_y, test_ys - explanatory variables, predictions and their uncertainties (test)\n",
    "#   RSS - residual  sum of squares\n",
    "#   title - plot title.\n",
    "def plot_fit(ax, w, data_x, data_y, data_ys, \n",
    "             test_x=None, test_y=None, test_ys=None,\n",
    "             RSS=None, title=None):\n",
    "    xmin, xmax = np.min(data_x[:, 0]), np.max(data_x[:, 0])\n",
    "    if test_x is not None:\n",
    "        test_min, test_max = np.min(test_x[:, 0]), np.max(test_x[:, 0])\n",
    "        xmin = min(xmin, test_min)\n",
    "        xmax = max(xmax, test_max)\n",
    "    \n",
    "    X = np.array([[xmin, 1], [xmax, 1]])\n",
    "    y = X @ w\n",
    "    \n",
    "    ax.errorbar(data_x[:, 0], data_y, data_ys, None, marker=\"o\", ls='', capsize=5)\n",
    "    if test_x is not None:\n",
    "        ax.errorbar(test_x[:, 0], test_y, test_ys, None, marker=\"x\", c='g', ls='', capsize=5);\n",
    "    \n",
    "    ax.plot(X[:, 0], y, marker='', lw=2.0, color='r');\n",
    "    \n",
    "    ax.set_xlabel('x', fontsize='xx-large')\n",
    "    ax.set_ylabel('y', fontsize='xx-large')\n",
    "    if RSS is not None:\n",
    "        ax.text(0.95, 0.01, 'Residual sum of squares: {0:0.1f}'.format(RSS),\n",
    "                verticalalignment='bottom', horizontalalignment='right',\n",
    "                transform=ax.transAxes, fontsize=15)\n",
    "    \n",
    "    if title is not None:\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot samples from a Bayesian linear regression\n",
    "#   ax - axis for plotting,\n",
    "#   w_samples - samples from the posterior over regression parameters\n",
    "#   data_x, data_y, data_ys - explanatory variables, responses and their uncertainties (data)\n",
    "#   title - plot title.\n",
    "def plot_posterior_samples(ax, w_samples, data_x, data_y, data_ys, title=None):\n",
    "    ax.errorbar(data_x[:, 0], data_y, data_ys, None, marker=\"o\", ls='', capsize=5)\n",
    "    ax.set_xlabel('x', fontsize='xx-large')\n",
    "    ax.set_ylabel('y', fontsize='xx-large')\n",
    "\n",
    "    xmin, xmax = np.min(data_x[:, 0]), np.max(data_x[:, 0])\n",
    "    X = np.array([[xmin, 1], [xmax, 1]])\n",
    "    \n",
    "    for w in w_samples:\n",
    "        y = X @ w\n",
    "        ax.plot(X[:, 0], y, marker='', lw=1.0, alpha=0.5, color='r');\n",
    "    \n",
    "    if title is not None:\n",
    "        ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# D.W. Hogg et al. Data analysis recipes: Fitting a model to data, https://arxiv.org/abs/1008.4686, 2010\n",
    "hogg_data = np.array([[201, 592, 61],\n",
    "                      [244, 401, 25],\n",
    "                      [47, 583, 38],\n",
    "                      [287, 402, 15],\n",
    "                      [203, 495, 21],\n",
    "                      [58, 173, 15],\n",
    "                      [210, 479, 27],\n",
    "                      [202, 504, 14],\n",
    "                      [198, 510, 30],\n",
    "                      [158, 416, 16],\n",
    "                      [165, 393, 14],\n",
    "                      [201, 442, 25],\n",
    "                      [157, 317, 52],\n",
    "                      [131, 311, 16],\n",
    "                      [166, 400, 34],\n",
    "                      [160, 337, 31],\n",
    "                      [186, 423, 42],\n",
    "                      [125, 334, 26],\n",
    "                      [218, 533, 16],\n",
    "                      [146, 344, 22]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formally, our model is:\n",
    "\n",
    "$y = \\mathbf{w}^\\mathsf{T}\\mathbf{x} + b + \\epsilon$\n",
    "\n",
    "However, we can get rid of the bias term $b$ by appending 1s to the explanatory variables and including $b$ in $w$:\n",
    "\n",
    "$\n",
    "\\mathbf{x} \\leftarrow [\\mathbf{x}, 1] \\\\\n",
    "\\mathbf{w} \\leftarrow [\\mathbf{w}, b]\n",
    "$\n",
    "\n",
    "Then our model becomes:\n",
    "\n",
    "$y = \\mathbf{w}^\\mathsf{T}\\mathbf{x} + \\epsilon$\n",
    "\n",
    "Now, lets pack all explanatory variables to a single matrix $\\mathbf{X}$ (each row of $\\mathbf{X}$ is a vector of explanatory variables for a single observation). We will then have a following model:\n",
    "\n",
    "$\\mathbf{y} = \\mathbf{X}\\mathbf{w} + \\boldsymbol \\epsilon$\n",
    "\n",
    "Let's prepare our data for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hogg_x, hogg_y, hogg_ys = hogg_data[:, 0], hogg_data[:, 1], hogg_data[:, 2]\n",
    "\n",
    "hogg_x, hogg_y = hogg_x[:, None], hogg_y[:, None]\n",
    "\n",
    "ones = np.ones((hogg_x.shape[0], 1))\n",
    "hogg_x = np.concatenate((hogg_x, ones), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('explanatory variable:')\n",
    "for x1, x2 in hogg_x[:3, :]:  \n",
    "       print('{0}\\t{1:.1f}'.format(x1, x2))\n",
    "print('...')\n",
    "\n",
    "print('\\nresponses:')\n",
    "for y in hogg_y[:3]:  \n",
    "       print('{0}'.format(y[0]))\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now, let's plot this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 7))\n",
    "plt.errorbar(hogg_x[:, 0], hogg_y, hogg_ys, None, marker=\"o\", ls='', capsize=5)\n",
    "plt.xlabel('x', fontsize='xx-large')\n",
    "plt.ylabel('y', fontsize='xx-large');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary least squares fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first task is to calculate an ordinary least squares fit to ``hogg_data``.\n",
    "\n",
    "Implement the `OLS` function, which:\n",
    "- takes as an input a matrix of explanatory variables and a vector of responses\n",
    "- and returns:\n",
    "  - maximum likelihood estimation of a linear regression fit to this data (i.e. OLS solution),\n",
    "  - residual sum of squares, i.e. $\\sum_{i=1}^n (y_i - \\mathbf{w}^\\mathsf{T}\\mathbf{x}_i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OLS(X, y):\n",
    "    raise Exception('Unimplemented')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate and plot an OLS fit. <br>\n",
    "Ordinary least squares disregards uncertainties in response variables, so we do not plot error bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w, RSS = OLS(hogg_x, hogg_y)\n",
    "\n",
    "fig = plt.figure(figsize=(14, 7))\n",
    "plot_fit(plt.gca(), w, hogg_x, hogg_y, 0, RSS=RSS, title='Ordinary least squares fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this a convincing fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gain insight into uncertainty of our fit, we must move to Bayesian modeling.\n",
    "\n",
    "Implement `bayes_lin_reg` function, which:\n",
    "- takes as an input:\n",
    "    - prior mean and covariance of the regression parameters $\\mathbf{w}$,\n",
    "    - response uncertainty ($\\sigma$ hyperparameter),\n",
    "    - matrix of explanatory variables and vector of responses,\n",
    "- and returns parameters of the posterior distribution over $\\mathbf{w}$ (mean and covariance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bayes_lin_reg(prior_mu, prior_Sigma, sigma, X, y):\n",
    "    raise Exception('Unimplemented')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to propose a reasonable prior for $\\mathbf{w}$.\n",
    "\n",
    "Propose and justify (in a comment) mean and covariance for the prior distribution over $\\mathbf{w}$. You can use an informative prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('Propose and justify (in a comment) mean and covariance for the prior distribution over w')\n",
    "\n",
    "# mu_0 = ???\n",
    "# Sigma_0 = ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to calculate posterior distributions over parameters of our linear regression fits.\n",
    "\n",
    "To gain an insight into behavior of these posteriors, we will plot:\n",
    "- Prior.\n",
    "- Posterior after observing just one data point. <br>\n",
    "  <u>Look at the distribution of the regression slope (when we know just one data point). Write your conclusions about this distribution in a comment below the plots</u>.\n",
    "- Posterior after observing 5 data points.\n",
    "- Posterior after observing all data points.\n",
    "\n",
    "<u>Why these posteriors are oriented \"diagonally\". Answer in a comment below the plots</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_posteriors():\n",
    "    mu_1, Sigma_1 = bayes_lin_reg(mu_0, Sigma_0, sigma, hogg_x[:1], hogg_y[:1])\n",
    "    mu_5, Sigma_5 = bayes_lin_reg(mu_1, Sigma_1, sigma, hogg_x[1:10], hogg_y[1:10])\n",
    "    mu_n, Sigma_n = bayes_lin_reg(mu_5, Sigma_5, sigma, hogg_x[5:], hogg_y[5:])\n",
    "    \n",
    "    _, ax = plt.subplots(2, 2, figsize=(8,8))\n",
    "    plot_mvn(ax[0, 0], mu_0, Sigma_0, title='Prior')\n",
    "    plot_mvn(ax[0, 1], mu_1, Sigma_1, title='Posterior after 1 observation')\n",
    "    plot_mvn(ax[1, 0], mu_5, Sigma_5, title='Posterior after 5 observations')\n",
    "    plot_mvn(ax[1, 1], mu_n, Sigma_n, title='Posterior after all observations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with posteriors when response uncertainty $\\sigma = 25.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 25.\n",
    "\n",
    "plot_posteriors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when response uncertainty increases to $\\sigma = 100.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 100.\n",
    "\n",
    "plot_posteriors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAP fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another point estimate for $\\mathbf{w}$ - maximum a posteriori estimate.\n",
    "\n",
    "First, we calculate a posterior distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma = 25.\n",
    "\n",
    "mu_n, Sigma_n = bayes_lin_reg(mu_0, Sigma_0, sigma, hogg_x, hogg_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, find the MAP estimate for $\\mathbf{w}$ and store it in `w_map`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('Find the MAP estimate for w and store it in w_map.')\n",
    "\n",
    "# w_map = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this MAP fit. We will use $\\sigma$ as response uncertainty (error bars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 7))\n",
    "ax = plt.gca()\n",
    "\n",
    "plot_fit(ax, w_map, hogg_x, hogg_y, sigma, title='MAP fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this fit convincing? How does it compare to OLS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty in our fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a simple way to judge the uncertainty in our regression fits - we can draw many samples from the posterior over $\\mathbf{w}$ and then plot them together.\n",
    "\n",
    "Let's start by calculating the posterior again. For now we assume that response uncertainty is $\\sigma = 25.0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma = 25.\n",
    "\n",
    "mu_n, Sigma_n = bayes_lin_reg(mu_0, Sigma_0, sigma, hogg_x, hogg_y)\n",
    "mu_n = np.squeeze(mu_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, generate 50 samples from the posterior. Store them in `w_samples_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('Generate 50 samples from the posterior over w and store them in w_samples_1.')\n",
    "\n",
    "# w_samples_1 = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot these samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 7))\n",
    "plot_posterior_samples(plt.gca(), w_samples_1, hogg_x, hogg_y, sigma, title='Posterior samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would happen if response uncertainty was $\\sigma = 100.0$? Would this increase uncertainty in our fits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma = 100.\n",
    "\n",
    "mu_n, Sigma_n = bayes_lin_reg(mu_0, Sigma_0, sigma, hogg_x, hogg_y)\n",
    "mu_n = np.squeeze(mu_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 50 samples from this new posterior and store them in `w_samples_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('Generate 50 samples from the new posterior over w and store them in w_samples_2.')\n",
    "\n",
    "# w_samples_2 = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 7))\n",
    "plot_posterior_samples(plt.gca(), w_samples_2, hogg_x, hogg_y, sigma, title='Posterior samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the fit uncertainty increase?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior predictive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's do some predictions for new (previously unobserved) data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = np.array([[-150, 1],\n",
    "                   [130, 1],\n",
    "                   [280, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement `posterior_predictive` function, which:\n",
    "- takes as an input:\n",
    "    - posterior mean and covariance of the regression parameters $\\mathbf{w}$\n",
    "      (i.e. $\\boldsymbol \\mu_n$ and $\\boldsymbol \\Sigma_n$),\n",
    "    - response uncertainty ($\\sigma$ hyperparameter),\n",
    "    - a vector of explanatory variables $\\mathbf{x}$,\n",
    "- and returns parameters of the posterior predictive distribution\n",
    "  $p(y \\mid \\mathbf{x}, \\boldsymbol \\mu_n, \\boldsymbol \\Sigma_n, \\sigma)$<br>\n",
    "\n",
    "This posterior predictive distribution describes our believs about the response $y$ predicted for the input $\\mathbf{x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def posterior_predictive(posterior_mu, posterior_Sigma, sigma, x):\n",
    "    raise Exception('Unimplemented')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's calculate posterior over $\\mathbf{w}$ (assuming $\\sigma = 25.0$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma = 25.\n",
    "mu_n, Sigma_n = bayes_lin_reg(mu_0, Sigma_0, sigma, hogg_x, hogg_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and use it to make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_mu, y_sigma = np.empty(3), np.empty(3)\n",
    "for idx, x in enumerate(test_x):\n",
    "    y_mu[idx], y_sigma[idx] = posterior_predictive(mu_n, Sigma_n, sigma, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot our predictions. We plot:\n",
    "  - expected value of $y$,\n",
    "  - uncertainty about the predicted $y$, i.e. one standard deviation of $y$ (error bars),\n",
    "  - mean posterior fit to the (training) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 7))\n",
    "ax = plt.gca()\n",
    "plot_fit(ax, mu_n, hogg_x, hogg_y, sigma,\n",
    "         test_x=test_x, test_y=y_mu, test_ys=y_sigma,\n",
    "         title='Mean fit & posterior predictives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that:\n",
    "  - expected value of the predicted $y$ lies exactly on the posterior mean fit.\n",
    "  - when we make predictions away from the data points our uncertainty about predicted value increases."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Random.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
